INFO:root:###########################################
INFO:root:experiment_name: pip_32_16_60_r18_l2_l1_10_1_nb10
INFO:root:data_name: WFLW
INFO:root:det_head: pip
INFO:root:net_stride: 32
INFO:root:batch_size: 16
INFO:root:init_lr: 0.0001
INFO:root:num_epochs: 60
INFO:root:decay_steps: [30, 50]
INFO:root:input_size: 256
INFO:root:backbone: resnet18
INFO:root:pretrained: True
INFO:root:criterion_cls: l2
INFO:root:criterion_reg: l1
INFO:root:cls_loss_weight: 10
INFO:root:reg_loss_weight: 1
INFO:root:num_lms: 98
INFO:root:save_interval: 60
INFO:root:num_nb: 10
INFO:root:use_gpu: True
INFO:root:gpu_id: 2
INFO:root:###########################################
INFO:root:Epoch 0/59
INFO:root:----------
INFO:root:###########################################
INFO:root:experiment_name: pip_32_16_60_r18_l2_l1_10_1_nb10
INFO:root:data_name: WFLW
INFO:root:det_head: pip
INFO:root:net_stride: 32
INFO:root:batch_size: 16
INFO:root:init_lr: 0.0001
INFO:root:num_epochs: 60
INFO:root:decay_steps: [30, 50]
INFO:root:input_size: 256
INFO:root:backbone: resnet18
INFO:root:pretrained: True
INFO:root:criterion_cls: l2
INFO:root:criterion_reg: l1
INFO:root:cls_loss_weight: 10
INFO:root:reg_loss_weight: 1
INFO:root:num_lms: 98
INFO:root:save_interval: 60
INFO:root:num_nb: 10
INFO:root:use_gpu: True
INFO:root:gpu_id: 2
INFO:root:###########################################
INFO:root:Epoch 0/59
INFO:root:----------
INFO:root:###########################################
INFO:root:experiment_name: pip_32_16_60_r18_l2_l1_10_1_nb10
INFO:root:data_name: WFLW
INFO:root:det_head: pip
INFO:root:net_stride: 32
INFO:root:batch_size: 16
INFO:root:init_lr: 0.0001
INFO:root:num_epochs: 60
INFO:root:decay_steps: [30, 50]
INFO:root:input_size: 256
INFO:root:backbone: resnet18
INFO:root:pretrained: True
INFO:root:criterion_cls: l2
INFO:root:criterion_reg: l1
INFO:root:cls_loss_weight: 10
INFO:root:reg_loss_weight: 1
INFO:root:num_lms: 98
INFO:root:save_interval: 60
INFO:root:num_nb: 10
INFO:root:use_gpu: True
INFO:root:gpu_id: 2
INFO:root:###########################################
INFO:root:Epoch 0/59
INFO:root:----------
INFO:root:###########################################
INFO:root:experiment_name: pip_32_16_60_r18_l2_l1_10_1_nb10
INFO:root:data_name: WFLW
INFO:root:det_head: pip
INFO:root:net_stride: 32
INFO:root:batch_size: 16
INFO:root:init_lr: 0.0001
INFO:root:num_epochs: 60
INFO:root:decay_steps: [30, 50]
INFO:root:input_size: 256
INFO:root:backbone: resnet18
INFO:root:pretrained: True
INFO:root:criterion_cls: l2
INFO:root:criterion_reg: l1
INFO:root:cls_loss_weight: 10
INFO:root:reg_loss_weight: 1
INFO:root:num_lms: 98
INFO:root:save_interval: 60
INFO:root:num_nb: 10
INFO:root:use_gpu: True
INFO:root:gpu_id: 2
INFO:root:###########################################
INFO:root:Epoch 0/59
INFO:root:----------
INFO:root:###########################################
INFO:root:experiment_name: pip_32_16_60_r18_l2_l1_10_1_nb10
INFO:root:data_name: WFLW
INFO:root:det_head: pip
INFO:root:net_stride: 32
INFO:root:batch_size: 16
INFO:root:init_lr: 0.0001
INFO:root:num_epochs: 60
INFO:root:decay_steps: [30, 50]
INFO:root:input_size: 256
INFO:root:backbone: resnet18
INFO:root:pretrained: True
INFO:root:criterion_cls: l2
INFO:root:criterion_reg: l1
INFO:root:cls_loss_weight: 10
INFO:root:reg_loss_weight: 1
INFO:root:num_lms: 98
INFO:root:save_interval: 60
INFO:root:num_nb: 10
INFO:root:use_gpu: True
INFO:root:gpu_id: 2
INFO:root:###########################################
INFO:root:Epoch 0/59
INFO:root:----------
INFO:root:###########################################
INFO:root:experiment_name: pip_32_16_60_r18_l2_l1_10_1_nb10
INFO:root:data_name: WFLW
INFO:root:det_head: pip
INFO:root:net_stride: 32
INFO:root:batch_size: 16
INFO:root:init_lr: 0.0001
INFO:root:num_epochs: 60
INFO:root:decay_steps: [30, 50]
INFO:root:input_size: 256
INFO:root:backbone: resnet18
INFO:root:pretrained: True
INFO:root:criterion_cls: l2
INFO:root:criterion_reg: l1
INFO:root:cls_loss_weight: 10
INFO:root:reg_loss_weight: 1
INFO:root:num_lms: 98
INFO:root:save_interval: 60
INFO:root:num_nb: 10
INFO:root:use_gpu: True
INFO:root:gpu_id: 2
INFO:root:###########################################
INFO:root:Epoch 0/59
INFO:root:----------
INFO:root:###########################################
INFO:root:experiment_name: pip_32_16_60_r18_l2_l1_10_1_nb10
INFO:root:data_name: WFLW
INFO:root:det_head: pip
INFO:root:net_stride: 32
INFO:root:batch_size: 16
INFO:root:init_lr: 0.0001
INFO:root:num_epochs: 60
INFO:root:decay_steps: [30, 50]
INFO:root:input_size: 256
INFO:root:backbone: resnet18
INFO:root:pretrained: True
INFO:root:criterion_cls: l2
INFO:root:criterion_reg: l1
INFO:root:cls_loss_weight: 10
INFO:root:reg_loss_weight: 1
INFO:root:num_lms: 98
INFO:root:save_interval: 60
INFO:root:num_nb: 10
INFO:root:use_gpu: True
INFO:root:gpu_id: 2
INFO:root:###########################################
INFO:root:Epoch 0/59
INFO:root:----------
INFO:root:###########################################
INFO:root:experiment_name: pip_32_16_60_r18_l2_l1_10_1_nb10
INFO:root:data_name: WFLW
INFO:root:det_head: pip
INFO:root:net_stride: 32
INFO:root:batch_size: 16
INFO:root:init_lr: 0.0001
INFO:root:num_epochs: 60
INFO:root:decay_steps: [30, 50]
INFO:root:input_size: 256
INFO:root:backbone: resnet18
INFO:root:pretrained: True
INFO:root:criterion_cls: l2
INFO:root:criterion_reg: l1
INFO:root:cls_loss_weight: 10
INFO:root:reg_loss_weight: 1
INFO:root:num_lms: 98
INFO:root:save_interval: 60
INFO:root:num_nb: 10
INFO:root:use_gpu: True
INFO:root:gpu_id: 2
INFO:root:###########################################
INFO:root:Epoch 0/59
INFO:root:----------
INFO:root:[Epoch 0/59, Batch 0/467] <Total loss: 2.553404> <map loss: 0.168444> <x loss: 0.511848> <y loss: 0.506873> <nbx loss: 0.703067> <nby loss: 0.663172>
INFO:root:[Epoch 0/59, Batch 10/467] <Total loss: 1.532020> <map loss: 0.152725> <x loss: 0.280339> <y loss: 0.281840> <nbx loss: 0.406401> <nby loss: 0.410714>
INFO:root:[Epoch 0/59, Batch 20/467] <Total loss: 1.357671> <map loss: 0.146801> <x loss: 0.268410> <y loss: 0.247780> <nbx loss: 0.368889> <nby loss: 0.325792>
INFO:root:[Epoch 0/59, Batch 30/467] <Total loss: 1.229964> <map loss: 0.144115> <x loss: 0.251050> <y loss: 0.229219> <nbx loss: 0.332257> <nby loss: 0.273323>
INFO:root:[Epoch 0/59, Batch 40/467] <Total loss: 1.172267> <map loss: 0.138714> <x loss: 0.242185> <y loss: 0.215779> <nbx loss: 0.315688> <nby loss: 0.259902>
INFO:root:[Epoch 0/59, Batch 50/467] <Total loss: 1.124753> <map loss: 0.135019> <x loss: 0.231510> <y loss: 0.195980> <nbx loss: 0.312043> <nby loss: 0.250202>
INFO:root:[Epoch 0/59, Batch 60/467] <Total loss: 1.115976> <map loss: 0.131580> <x loss: 0.228382> <y loss: 0.190957> <nbx loss: 0.314084> <nby loss: 0.250973>
INFO:root:[Epoch 0/59, Batch 70/467] <Total loss: 1.091205> <map loss: 0.127376> <x loss: 0.224520> <y loss: 0.179341> <nbx loss: 0.307963> <nby loss: 0.252005>
INFO:root:[Epoch 0/59, Batch 80/467] <Total loss: 0.925356> <map loss: 0.117143> <x loss: 0.203738> <y loss: 0.157321> <nbx loss: 0.248314> <nby loss: 0.198839>
INFO:root:[Epoch 0/59, Batch 90/467] <Total loss: 0.942904> <map loss: 0.116532> <x loss: 0.195582> <y loss: 0.163665> <nbx loss: 0.263496> <nby loss: 0.203629>
INFO:root:[Epoch 0/59, Batch 100/467] <Total loss: 0.836889> <map loss: 0.109366> <x loss: 0.169931> <y loss: 0.155841> <nbx loss: 0.209679> <nby loss: 0.192071>
INFO:root:[Epoch 0/59, Batch 110/467] <Total loss: 0.777867> <map loss: 0.106975> <x loss: 0.157142> <y loss: 0.147291> <nbx loss: 0.190209> <nby loss: 0.176249>
INFO:root:[Epoch 0/59, Batch 120/467] <Total loss: 0.772251> <map loss: 0.103797> <x loss: 0.153715> <y loss: 0.149859> <nbx loss: 0.192560> <nby loss: 0.172320>
INFO:root:[Epoch 0/59, Batch 130/467] <Total loss: 0.701274> <map loss: 0.097368> <x loss: 0.143631> <y loss: 0.131126> <nbx loss: 0.174461> <nby loss: 0.154688>
INFO:root:[Epoch 0/59, Batch 140/467] <Total loss: 0.734051> <map loss: 0.100580> <x loss: 0.152515> <y loss: 0.131953> <nbx loss: 0.190790> <nby loss: 0.158213>
INFO:root:[Epoch 0/59, Batch 150/467] <Total loss: 0.778259> <map loss: 0.100715> <x loss: 0.161152> <y loss: 0.145123> <nbx loss: 0.195341> <nby loss: 0.175927>
INFO:root:[Epoch 0/59, Batch 160/467] <Total loss: 0.652803> <map loss: 0.091722> <x loss: 0.128022> <y loss: 0.130880> <nbx loss: 0.151593> <nby loss: 0.150587>
INFO:root:[Epoch 0/59, Batch 170/467] <Total loss: 0.696136> <map loss: 0.094613> <x loss: 0.145928> <y loss: 0.128072> <nbx loss: 0.174900> <nby loss: 0.152623>
INFO:root:[Epoch 0/59, Batch 180/467] <Total loss: 0.700323> <map loss: 0.095566> <x loss: 0.149392> <y loss: 0.131491> <nbx loss: 0.173624> <nby loss: 0.150250>
INFO:root:[Epoch 0/59, Batch 190/467] <Total loss: 0.662219> <map loss: 0.089663> <x loss: 0.135514> <y loss: 0.130805> <nbx loss: 0.156618> <nby loss: 0.149619>
INFO:root:[Epoch 0/59, Batch 200/467] <Total loss: 0.707728> <map loss: 0.095697> <x loss: 0.142713> <y loss: 0.136912> <nbx loss: 0.173152> <nby loss: 0.159254>
INFO:root:[Epoch 0/59, Batch 210/467] <Total loss: 0.642761> <map loss: 0.090476> <x loss: 0.131171> <y loss: 0.125099> <nbx loss: 0.152058> <nby loss: 0.143956>
INFO:root:[Epoch 0/59, Batch 220/467] <Total loss: 0.621001> <map loss: 0.089645> <x loss: 0.130270> <y loss: 0.119771> <nbx loss: 0.149733> <nby loss: 0.131581>
INFO:root:[Epoch 0/59, Batch 230/467] <Total loss: 0.655844> <map loss: 0.092233> <x loss: 0.128213> <y loss: 0.128485> <nbx loss: 0.155616> <nby loss: 0.151296>
INFO:root:[Epoch 0/59, Batch 240/467] <Total loss: 0.739616> <map loss: 0.097367> <x loss: 0.149184> <y loss: 0.143297> <nbx loss: 0.183410> <nby loss: 0.166358>
INFO:root:[Epoch 0/59, Batch 250/467] <Total loss: 0.590697> <map loss: 0.086156> <x loss: 0.124277> <y loss: 0.109160> <nbx loss: 0.147679> <nby loss: 0.123425>
INFO:root:[Epoch 0/59, Batch 260/467] <Total loss: 0.743024> <map loss: 0.095144> <x loss: 0.153745> <y loss: 0.144970> <nbx loss: 0.183858> <nby loss: 0.165307>
INFO:root:[Epoch 0/59, Batch 270/467] <Total loss: 0.617942> <map loss: 0.085608> <x loss: 0.126271> <y loss: 0.126978> <nbx loss: 0.138630> <nby loss: 0.140455>
INFO:root:[Epoch 0/59, Batch 280/467] <Total loss: 0.660992> <map loss: 0.090212> <x loss: 0.136538> <y loss: 0.125892> <nbx loss: 0.166527> <nby loss: 0.141821>
INFO:root:[Epoch 0/59, Batch 290/467] <Total loss: 0.600241> <map loss: 0.083412> <x loss: 0.128111> <y loss: 0.111108> <nbx loss: 0.151217> <nby loss: 0.126393>
INFO:root:[Epoch 0/59, Batch 300/467] <Total loss: 0.587861> <map loss: 0.084818> <x loss: 0.124653> <y loss: 0.104806> <nbx loss: 0.150868> <nby loss: 0.122715>
INFO:root:[Epoch 0/59, Batch 310/467] <Total loss: 0.625769> <map loss: 0.086544> <x loss: 0.135415> <y loss: 0.112567> <nbx loss: 0.163921> <nby loss: 0.127322>
INFO:root:[Epoch 0/59, Batch 320/467] <Total loss: 0.623174> <map loss: 0.088184> <x loss: 0.127897> <y loss: 0.122448> <nbx loss: 0.147800> <nby loss: 0.136844>
INFO:root:[Epoch 0/59, Batch 330/467] <Total loss: 0.644275> <map loss: 0.085307> <x loss: 0.134828> <y loss: 0.130634> <nbx loss: 0.151090> <nby loss: 0.142416>
INFO:root:[Epoch 0/59, Batch 340/467] <Total loss: 0.619505> <map loss: 0.086333> <x loss: 0.116300> <y loss: 0.132181> <nbx loss: 0.133996> <nby loss: 0.150694>
INFO:root:[Epoch 0/59, Batch 350/467] <Total loss: 0.558603> <map loss: 0.077162> <x loss: 0.119770> <y loss: 0.106129> <nbx loss: 0.138976> <nby loss: 0.116566>
INFO:root:[Epoch 0/59, Batch 360/467] <Total loss: 0.596183> <map loss: 0.083171> <x loss: 0.127658> <y loss: 0.112531> <nbx loss: 0.148272> <nby loss: 0.124551>
INFO:root:[Epoch 0/59, Batch 370/467] <Total loss: 0.568627> <map loss: 0.078953> <x loss: 0.120641> <y loss: 0.108959> <nbx loss: 0.138375> <nby loss: 0.121699>
INFO:root:[Epoch 0/59, Batch 380/467] <Total loss: 0.590460> <map loss: 0.081737> <x loss: 0.122252> <y loss: 0.117657> <nbx loss: 0.136661> <nby loss: 0.132153>
INFO:root:[Epoch 0/59, Batch 390/467] <Total loss: 0.647477> <map loss: 0.088282> <x loss: 0.132934> <y loss: 0.124224> <nbx loss: 0.160221> <nby loss: 0.141815>
INFO:root:[Epoch 0/59, Batch 400/467] <Total loss: 0.586580> <map loss: 0.078485> <x loss: 0.128309> <y loss: 0.110669> <nbx loss: 0.142191> <nby loss: 0.126926>
INFO:root:[Epoch 0/59, Batch 410/467] <Total loss: 0.646580> <map loss: 0.089948> <x loss: 0.139178> <y loss: 0.127641> <nbx loss: 0.155316> <nby loss: 0.134496>
INFO:root:[Epoch 0/59, Batch 420/467] <Total loss: 0.604862> <map loss: 0.081742> <x loss: 0.133199> <y loss: 0.111857> <nbx loss: 0.155999> <nby loss: 0.122065>
INFO:root:[Epoch 0/59, Batch 430/467] <Total loss: 0.599369> <map loss: 0.080454> <x loss: 0.124664> <y loss: 0.117674> <nbx loss: 0.146595> <nby loss: 0.129983>
INFO:root:[Epoch 0/59, Batch 440/467] <Total loss: 0.628521> <map loss: 0.083650> <x loss: 0.129893> <y loss: 0.122409> <nbx loss: 0.152145> <nby loss: 0.140424>
INFO:root:[Epoch 0/59, Batch 450/467] <Total loss: 0.583876> <map loss: 0.076590> <x loss: 0.130108> <y loss: 0.110463> <nbx loss: 0.144254> <nby loss: 0.122460>
INFO:root:[Epoch 0/59, Batch 460/467] <Total loss: 0.553091> <map loss: 0.076603> <x loss: 0.124404> <y loss: 0.102824> <nbx loss: 0.136071> <nby loss: 0.113190>
INFO:root:Epoch 1/59
INFO:root:----------
INFO:root:[Epoch 1/59, Batch 0/467] <Total loss: 0.584284> <map loss: 0.080754> <x loss: 0.129574> <y loss: 0.108569> <nbx loss: 0.147295> <nby loss: 0.118092>
INFO:root:[Epoch 1/59, Batch 10/467] <Total loss: 0.547469> <map loss: 0.076880> <x loss: 0.120652> <y loss: 0.105084> <nbx loss: 0.131363> <nby loss: 0.113491>
INFO:root:[Epoch 1/59, Batch 20/467] <Total loss: 0.543932> <map loss: 0.076910> <x loss: 0.122235> <y loss: 0.097360> <nbx loss: 0.139519> <nby loss: 0.107908>
INFO:root:[Epoch 1/59, Batch 30/467] <Total loss: 0.509382> <map loss: 0.072575> <x loss: 0.109913> <y loss: 0.098479> <nbx loss: 0.125679> <nby loss: 0.102736>
INFO:root:[Epoch 1/59, Batch 40/467] <Total loss: 0.505078> <map loss: 0.073563> <x loss: 0.111428> <y loss: 0.093673> <nbx loss: 0.126091> <nby loss: 0.100323>
INFO:root:[Epoch 1/59, Batch 50/467] <Total loss: 0.577561> <map loss: 0.081289> <x loss: 0.117476> <y loss: 0.113262> <nbx loss: 0.138371> <nby loss: 0.127163>
INFO:root:[Epoch 1/59, Batch 60/467] <Total loss: 0.559093> <map loss: 0.077508> <x loss: 0.123928> <y loss: 0.101930> <nbx loss: 0.138412> <nby loss: 0.117315>
INFO:root:[Epoch 1/59, Batch 70/467] <Total loss: 0.564081> <map loss: 0.079315> <x loss: 0.127844> <y loss: 0.105051> <nbx loss: 0.140826> <nby loss: 0.111044>
INFO:root:[Epoch 1/59, Batch 80/467] <Total loss: 0.551375> <map loss: 0.075799> <x loss: 0.116058> <y loss: 0.109898> <nbx loss: 0.131141> <nby loss: 0.118479>
INFO:root:[Epoch 1/59, Batch 90/467] <Total loss: 0.508892> <map loss: 0.074050> <x loss: 0.106464> <y loss: 0.100012> <nbx loss: 0.119236> <nby loss: 0.109130>
INFO:root:[Epoch 1/59, Batch 100/467] <Total loss: 0.568217> <map loss: 0.078044> <x loss: 0.126528> <y loss: 0.106480> <nbx loss: 0.142977> <nby loss: 0.114188>
INFO:root:[Epoch 1/59, Batch 110/467] <Total loss: 0.523462> <map loss: 0.072544> <x loss: 0.116580> <y loss: 0.098100> <nbx loss: 0.130512> <nby loss: 0.105725>
INFO:root:[Epoch 1/59, Batch 120/467] <Total loss: 0.578854> <map loss: 0.078507> <x loss: 0.130451> <y loss: 0.106818> <nbx loss: 0.149341> <nby loss: 0.113737>
INFO:root:[Epoch 1/59, Batch 130/467] <Total loss: 0.596751> <map loss: 0.078887> <x loss: 0.126552> <y loss: 0.115871> <nbx loss: 0.142961> <nby loss: 0.132480>
INFO:root:[Epoch 1/59, Batch 140/467] <Total loss: 0.477475> <map loss: 0.067140> <x loss: 0.099035> <y loss: 0.097358> <nbx loss: 0.110336> <nby loss: 0.103607>
INFO:root:[Epoch 1/59, Batch 150/467] <Total loss: 0.528842> <map loss: 0.073410> <x loss: 0.111692> <y loss: 0.099310> <nbx loss: 0.132605> <nby loss: 0.111825>
INFO:root:[Epoch 1/59, Batch 160/467] <Total loss: 0.544245> <map loss: 0.071679> <x loss: 0.114523> <y loss: 0.112988> <nbx loss: 0.125797> <nby loss: 0.119258>
INFO:root:[Epoch 1/59, Batch 170/467] <Total loss: 0.474932> <map loss: 0.069774> <x loss: 0.097033> <y loss: 0.098390> <nbx loss: 0.108128> <nby loss: 0.101606>
INFO:root:[Epoch 1/59, Batch 180/467] <Total loss: 0.612662> <map loss: 0.078755> <x loss: 0.132156> <y loss: 0.121573> <nbx loss: 0.148431> <nby loss: 0.131746>
INFO:root:[Epoch 1/59, Batch 190/467] <Total loss: 0.494863> <map loss: 0.068180> <x loss: 0.108563> <y loss: 0.097880> <nbx loss: 0.117076> <nby loss: 0.103164>
INFO:root:[Epoch 1/59, Batch 200/467] <Total loss: 0.532819> <map loss: 0.072045> <x loss: 0.112013> <y loss: 0.108652> <nbx loss: 0.126789> <nby loss: 0.113320>
INFO:root:[Epoch 1/59, Batch 210/467] <Total loss: 0.555668> <map loss: 0.074085> <x loss: 0.120843> <y loss: 0.106801> <nbx loss: 0.136751> <nby loss: 0.117189>
INFO:root:[Epoch 1/59, Batch 220/467] <Total loss: 0.533265> <map loss: 0.072828> <x loss: 0.122792> <y loss: 0.100553> <nbx loss: 0.134592> <nby loss: 0.102500>
INFO:root:[Epoch 1/59, Batch 230/467] <Total loss: 0.500412> <map loss: 0.070767> <x loss: 0.104945> <y loss: 0.101982> <nbx loss: 0.116900> <nby loss: 0.105818>
INFO:root:[Epoch 1/59, Batch 240/467] <Total loss: 0.522491> <map loss: 0.072323> <x loss: 0.113002> <y loss: 0.104923> <nbx loss: 0.123910> <nby loss: 0.108333>
INFO:root:[Epoch 1/59, Batch 250/467] <Total loss: 0.569409> <map loss: 0.077416> <x loss: 0.113285> <y loss: 0.117246> <nbx loss: 0.130866> <nby loss: 0.130596>
INFO:root:[Epoch 1/59, Batch 260/467] <Total loss: 0.545959> <map loss: 0.076645> <x loss: 0.113217> <y loss: 0.109493> <nbx loss: 0.126561> <nby loss: 0.120043>
INFO:root:[Epoch 1/59, Batch 270/467] <Total loss: 0.511684> <map loss: 0.071958> <x loss: 0.112178> <y loss: 0.098503> <nbx loss: 0.127388> <nby loss: 0.101657>
INFO:root:[Epoch 1/59, Batch 280/467] <Total loss: 0.535595> <map loss: 0.074231> <x loss: 0.114915> <y loss: 0.106928> <nbx loss: 0.126812> <nby loss: 0.112709>
INFO:root:[Epoch 1/59, Batch 290/467] <Total loss: 0.600619> <map loss: 0.078650> <x loss: 0.127089> <y loss: 0.112709> <nbx loss: 0.152496> <nby loss: 0.129675>
INFO:root:[Epoch 1/59, Batch 300/467] <Total loss: 0.540559> <map loss: 0.073991> <x loss: 0.111270> <y loss: 0.111199> <nbx loss: 0.125547> <nby loss: 0.118552>
INFO:root:[Epoch 1/59, Batch 310/467] <Total loss: 0.525873> <map loss: 0.072869> <x loss: 0.116975> <y loss: 0.094175> <nbx loss: 0.136591> <nby loss: 0.105264>
INFO:root:[Epoch 1/59, Batch 320/467] <Total loss: 0.515019> <map loss: 0.070890> <x loss: 0.111753> <y loss: 0.096025> <nbx loss: 0.130562> <nby loss: 0.105789>
INFO:root:[Epoch 1/59, Batch 330/467] <Total loss: 0.542649> <map loss: 0.072430> <x loss: 0.116477> <y loss: 0.104340> <nbx loss: 0.135398> <nby loss: 0.114003>
INFO:root:[Epoch 1/59, Batch 340/467] <Total loss: 0.561362> <map loss: 0.073163> <x loss: 0.126011> <y loss: 0.105056> <nbx loss: 0.144213> <nby loss: 0.112920>
INFO:root:[Epoch 1/59, Batch 350/467] <Total loss: 0.605483> <map loss: 0.079362> <x loss: 0.136469> <y loss: 0.111008> <nbx loss: 0.158579> <nby loss: 0.120066>
INFO:root:[Epoch 1/59, Batch 360/467] <Total loss: 0.489938> <map loss: 0.063533> <x loss: 0.109236> <y loss: 0.095333> <nbx loss: 0.116260> <nby loss: 0.105576>
INFO:root:[Epoch 1/59, Batch 370/467] <Total loss: 0.497377> <map loss: 0.070005> <x loss: 0.104860> <y loss: 0.102320> <nbx loss: 0.112689> <nby loss: 0.107503>
INFO:root:[Epoch 1/59, Batch 380/467] <Total loss: 0.510286> <map loss: 0.071032> <x loss: 0.110262> <y loss: 0.099719> <nbx loss: 0.121975> <nby loss: 0.107299>
INFO:root:[Epoch 1/59, Batch 390/467] <Total loss: 0.458269> <map loss: 0.061319> <x loss: 0.104595> <y loss: 0.086575> <nbx loss: 0.116840> <nby loss: 0.088939>
INFO:root:[Epoch 1/59, Batch 400/467] <Total loss: 0.549623> <map loss: 0.072767> <x loss: 0.119302> <y loss: 0.100846> <nbx loss: 0.142770> <nby loss: 0.113939>
INFO:root:[Epoch 1/59, Batch 410/467] <Total loss: 0.613847> <map loss: 0.079642> <x loss: 0.141824> <y loss: 0.110049> <nbx loss: 0.160922> <nby loss: 0.121410>
INFO:root:[Epoch 1/59, Batch 420/467] <Total loss: 0.470766> <map loss: 0.065805> <x loss: 0.110074> <y loss: 0.086214> <nbx loss: 0.119586> <nby loss: 0.089087>
INFO:root:[Epoch 1/59, Batch 430/467] <Total loss: 0.507883> <map loss: 0.069191> <x loss: 0.110157> <y loss: 0.100014> <nbx loss: 0.122690> <nby loss: 0.105831>
INFO:root:[Epoch 1/59, Batch 440/467] <Total loss: 0.553352> <map loss: 0.075068> <x loss: 0.120109> <y loss: 0.102895> <nbx loss: 0.139917> <nby loss: 0.115364>
INFO:root:[Epoch 1/59, Batch 450/467] <Total loss: 0.515154> <map loss: 0.073514> <x loss: 0.111588> <y loss: 0.099144> <nbx loss: 0.125781> <nby loss: 0.105127>
INFO:root:[Epoch 1/59, Batch 460/467] <Total loss: 0.469419> <map loss: 0.065082> <x loss: 0.104649> <y loss: 0.089083> <nbx loss: 0.116108> <nby loss: 0.094497>
INFO:root:Epoch 2/59
INFO:root:----------
INFO:root:[Epoch 2/59, Batch 0/467] <Total loss: 0.502126> <map loss: 0.068937> <x loss: 0.116737> <y loss: 0.090172> <nbx loss: 0.128499> <nby loss: 0.097780>
INFO:root:[Epoch 2/59, Batch 10/467] <Total loss: 0.536377> <map loss: 0.073373> <x loss: 0.118486> <y loss: 0.102601> <nbx loss: 0.134550> <nby loss: 0.107367>
INFO:root:[Epoch 2/59, Batch 20/467] <Total loss: 0.551237> <map loss: 0.072215> <x loss: 0.125681> <y loss: 0.100836> <nbx loss: 0.141428> <nby loss: 0.111077>
INFO:root:[Epoch 2/59, Batch 30/467] <Total loss: 0.488842> <map loss: 0.063956> <x loss: 0.109299> <y loss: 0.098079> <nbx loss: 0.115166> <nby loss: 0.102341>
INFO:root:[Epoch 2/59, Batch 40/467] <Total loss: 0.455485> <map loss: 0.065411> <x loss: 0.099616> <y loss: 0.090932> <nbx loss: 0.108694> <nby loss: 0.090832>
INFO:root:[Epoch 2/59, Batch 50/467] <Total loss: 0.537047> <map loss: 0.070001> <x loss: 0.122628> <y loss: 0.101647> <nbx loss: 0.135438> <nby loss: 0.107332>
INFO:root:[Epoch 2/59, Batch 60/467] <Total loss: 0.555467> <map loss: 0.073249> <x loss: 0.120166> <y loss: 0.107083> <nbx loss: 0.138196> <nby loss: 0.116773>
INFO:root:[Epoch 2/59, Batch 70/467] <Total loss: 0.492208> <map loss: 0.068161> <x loss: 0.106949> <y loss: 0.096928> <nbx loss: 0.115758> <nby loss: 0.104412>
INFO:root:[Epoch 2/59, Batch 80/467] <Total loss: 0.483467> <map loss: 0.068118> <x loss: 0.103373> <y loss: 0.096891> <nbx loss: 0.114009> <nby loss: 0.101077>
INFO:root:[Epoch 2/59, Batch 90/467] <Total loss: 0.504180> <map loss: 0.070931> <x loss: 0.109475> <y loss: 0.096986> <nbx loss: 0.126945> <nby loss: 0.099841>
INFO:root:[Epoch 2/59, Batch 100/467] <Total loss: 0.477461> <map loss: 0.068917> <x loss: 0.100079> <y loss: 0.096933> <nbx loss: 0.110836> <nby loss: 0.100696>
INFO:root:[Epoch 2/59, Batch 110/467] <Total loss: 0.581655> <map loss: 0.075851> <x loss: 0.130326> <y loss: 0.115559> <nbx loss: 0.141125> <nby loss: 0.118794>
INFO:root:[Epoch 2/59, Batch 120/467] <Total loss: 0.483020> <map loss: 0.071073> <x loss: 0.102865> <y loss: 0.094666> <nbx loss: 0.113583> <nby loss: 0.100833>
INFO:root:[Epoch 2/59, Batch 130/467] <Total loss: 0.542792> <map loss: 0.075267> <x loss: 0.114804> <y loss: 0.105567> <nbx loss: 0.130785> <nby loss: 0.116369>
INFO:root:[Epoch 2/59, Batch 140/467] <Total loss: 0.490047> <map loss: 0.068425> <x loss: 0.107171> <y loss: 0.094708> <nbx loss: 0.118683> <nby loss: 0.101060>
INFO:root:[Epoch 2/59, Batch 150/467] <Total loss: 0.575639> <map loss: 0.076935> <x loss: 0.129728> <y loss: 0.105209> <nbx loss: 0.150444> <nby loss: 0.113324>
INFO:root:###########################################
INFO:root:experiment_name: pip_32_16_60_r18_l2_l1_10_1_nb10
INFO:root:data_name: WFLW
INFO:root:det_head: pip
INFO:root:net_stride: 32
INFO:root:batch_size: 16
INFO:root:init_lr: 0.0001
INFO:root:num_epochs: 1
INFO:root:decay_steps: [30, 50]
INFO:root:input_size: 256
INFO:root:backbone: resnet18
INFO:root:pretrained: True
INFO:root:criterion_cls: l2
INFO:root:criterion_reg: l1
INFO:root:cls_loss_weight: 10
INFO:root:reg_loss_weight: 1
INFO:root:num_lms: 98
INFO:root:save_interval: 1
INFO:root:num_nb: 10
INFO:root:use_gpu: True
INFO:root:gpu_id: 2
INFO:root:###########################################
INFO:root:Epoch 0/0
INFO:root:----------
INFO:root:[Epoch 0/0, Batch 0/467] <Total loss: 2.502964> <map loss: 0.170364> <x loss: 0.491026> <y loss: 0.494771> <nbx loss: 0.685371> <nby loss: 0.661431>
INFO:root:[Epoch 0/0, Batch 10/467] <Total loss: 1.587182> <map loss: 0.153799> <x loss: 0.289638> <y loss: 0.276286> <nbx loss: 0.466041> <nby loss: 0.401419>
INFO:root:[Epoch 0/0, Batch 20/467] <Total loss: 1.370429> <map loss: 0.148830> <x loss: 0.264964> <y loss: 0.249547> <nbx loss: 0.365012> <nby loss: 0.342076>
INFO:root:[Epoch 0/0, Batch 30/467] <Total loss: 1.269350> <map loss: 0.143599> <x loss: 0.252027> <y loss: 0.233282> <nbx loss: 0.344312> <nby loss: 0.296130>
INFO:root:[Epoch 0/0, Batch 40/467] <Total loss: 1.178944> <map loss: 0.137971> <x loss: 0.237649> <y loss: 0.215687> <nbx loss: 0.317525> <nby loss: 0.270112>
INFO:root:[Epoch 0/0, Batch 50/467] <Total loss: 1.137464> <map loss: 0.134379> <x loss: 0.238649> <y loss: 0.201050> <nbx loss: 0.319285> <nby loss: 0.244102>
INFO:root:[Epoch 0/0, Batch 60/467] <Total loss: 1.098450> <map loss: 0.128986> <x loss: 0.231301> <y loss: 0.185292> <nbx loss: 0.318993> <nby loss: 0.233878>
INFO:root:[Epoch 0/0, Batch 70/467] <Total loss: 0.989181> <map loss: 0.124722> <x loss: 0.205416> <y loss: 0.171230> <nbx loss: 0.274696> <nby loss: 0.213117>
INFO:root:[Epoch 0/0, Batch 80/467] <Total loss: 0.952363> <map loss: 0.121622> <x loss: 0.197572> <y loss: 0.167713> <nbx loss: 0.257424> <nby loss: 0.208031>
INFO:root:[Epoch 0/0, Batch 90/467] <Total loss: 0.884918> <map loss: 0.116500> <x loss: 0.179478> <y loss: 0.156719> <nbx loss: 0.236135> <nby loss: 0.196086>
INFO:root:[Epoch 0/0, Batch 100/467] <Total loss: 0.817602> <map loss: 0.108073> <x loss: 0.169437> <y loss: 0.147896> <nbx loss: 0.217198> <nby loss: 0.174998>
INFO:root:[Epoch 0/0, Batch 110/467] <Total loss: 0.816101> <map loss: 0.107744> <x loss: 0.163212> <y loss: 0.157047> <nbx loss: 0.203233> <nby loss: 0.184865>
INFO:root:[Epoch 0/0, Batch 120/467] <Total loss: 0.806721> <map loss: 0.106589> <x loss: 0.164255> <y loss: 0.150762> <nbx loss: 0.204254> <nby loss: 0.180861>
INFO:root:[Epoch 0/0, Batch 130/467] <Total loss: 0.729413> <map loss: 0.097720> <x loss: 0.153136> <y loss: 0.135948> <nbx loss: 0.185470> <nby loss: 0.157139>
INFO:root:[Epoch 0/0, Batch 140/467] <Total loss: 0.707446> <map loss: 0.098794> <x loss: 0.142984> <y loss: 0.135073> <nbx loss: 0.168278> <nby loss: 0.162317>
INFO:root:[Epoch 0/0, Batch 150/467] <Total loss: 0.726915> <map loss: 0.097557> <x loss: 0.146791> <y loss: 0.141300> <nbx loss: 0.175238> <nby loss: 0.166029>
INFO:root:[Epoch 0/0, Batch 160/467] <Total loss: 0.682905> <map loss: 0.093544> <x loss: 0.144224> <y loss: 0.128043> <nbx loss: 0.167115> <nby loss: 0.149979>
INFO:root:[Epoch 0/0, Batch 170/467] <Total loss: 0.701680> <map loss: 0.098889> <x loss: 0.144040> <y loss: 0.129476> <nbx loss: 0.175584> <nby loss: 0.153690>
INFO:root:[Epoch 0/0, Batch 180/467] <Total loss: 0.683371> <map loss: 0.091163> <x loss: 0.146708> <y loss: 0.127922> <nbx loss: 0.170625> <nby loss: 0.146954>
INFO:root:[Epoch 0/0, Batch 190/467] <Total loss: 0.699276> <map loss: 0.096689> <x loss: 0.147965> <y loss: 0.126122> <nbx loss: 0.183422> <nby loss: 0.145079>
INFO:root:[Epoch 0/0, Batch 200/467] <Total loss: 0.693445> <map loss: 0.096980> <x loss: 0.138516> <y loss: 0.134624> <nbx loss: 0.167983> <nby loss: 0.155341>
INFO:root:[Epoch 0/0, Batch 210/467] <Total loss: 0.626781> <map loss: 0.089069> <x loss: 0.137583> <y loss: 0.112541> <nbx loss: 0.158835> <nby loss: 0.128753>
INFO:root:[Epoch 0/0, Batch 220/467] <Total loss: 0.647564> <map loss: 0.087144> <x loss: 0.141878> <y loss: 0.120016> <nbx loss: 0.160232> <nby loss: 0.138293>
INFO:root:[Epoch 0/0, Batch 230/467] <Total loss: 0.694893> <map loss: 0.090229> <x loss: 0.145914> <y loss: 0.139671> <nbx loss: 0.168995> <nby loss: 0.150083>
INFO:root:[Epoch 0/0, Batch 240/467] <Total loss: 0.652241> <map loss: 0.085122> <x loss: 0.137031> <y loss: 0.123147> <nbx loss: 0.157661> <nby loss: 0.149280>
INFO:root:[Epoch 0/0, Batch 250/467] <Total loss: 0.653764> <map loss: 0.090522> <x loss: 0.140166> <y loss: 0.125301> <nbx loss: 0.156214> <nby loss: 0.141562>
INFO:root:[Epoch 0/0, Batch 260/467] <Total loss: 0.637565> <map loss: 0.089066> <x loss: 0.138010> <y loss: 0.119567> <nbx loss: 0.159906> <nby loss: 0.131016>
INFO:root:[Epoch 0/0, Batch 270/467] <Total loss: 0.610702> <map loss: 0.088077> <x loss: 0.131439> <y loss: 0.112133> <nbx loss: 0.152837> <nby loss: 0.126216>
INFO:root:[Epoch 0/0, Batch 280/467] <Total loss: 0.594260> <map loss: 0.081777> <x loss: 0.135533> <y loss: 0.107079> <nbx loss: 0.153026> <nby loss: 0.116845>
INFO:root:[Epoch 0/0, Batch 290/467] <Total loss: 0.671605> <map loss: 0.089107> <x loss: 0.131628> <y loss: 0.135690> <nbx loss: 0.158400> <nby loss: 0.156780>
INFO:root:[Epoch 0/0, Batch 300/467] <Total loss: 0.584845> <map loss: 0.083382> <x loss: 0.126829> <y loss: 0.111102> <nbx loss: 0.144507> <nby loss: 0.119025>
INFO:root:[Epoch 0/0, Batch 310/467] <Total loss: 0.595262> <map loss: 0.084644> <x loss: 0.126847> <y loss: 0.112407> <nbx loss: 0.146553> <nby loss: 0.124813>
INFO:root:[Epoch 0/0, Batch 320/467] <Total loss: 0.637957> <map loss: 0.085131> <x loss: 0.135628> <y loss: 0.119313> <nbx loss: 0.156698> <nby loss: 0.141186>
INFO:root:[Epoch 0/0, Batch 330/467] <Total loss: 0.556892> <map loss: 0.079889> <x loss: 0.121392> <y loss: 0.103690> <nbx loss: 0.137059> <nby loss: 0.114862>
INFO:root:[Epoch 0/0, Batch 340/467] <Total loss: 0.569431> <map loss: 0.081895> <x loss: 0.119597> <y loss: 0.108516> <nbx loss: 0.140214> <nby loss: 0.119210>
INFO:root:[Epoch 0/0, Batch 350/467] <Total loss: 0.603165> <map loss: 0.084064> <x loss: 0.120251> <y loss: 0.115929> <nbx loss: 0.146128> <nby loss: 0.136793>
INFO:root:[Epoch 0/0, Batch 360/467] <Total loss: 0.582653> <map loss: 0.082298> <x loss: 0.122318> <y loss: 0.112509> <nbx loss: 0.144381> <nby loss: 0.121148>
INFO:root:[Epoch 0/0, Batch 370/467] <Total loss: 0.567973> <map loss: 0.079576> <x loss: 0.115171> <y loss: 0.112727> <nbx loss: 0.133205> <nby loss: 0.127294>
INFO:root:[Epoch 0/0, Batch 380/467] <Total loss: 0.639791> <map loss: 0.087974> <x loss: 0.138469> <y loss: 0.117627> <nbx loss: 0.160820> <nby loss: 0.134900>
INFO:root:[Epoch 0/0, Batch 390/467] <Total loss: 0.676758> <map loss: 0.088467> <x loss: 0.142754> <y loss: 0.134993> <nbx loss: 0.164225> <nby loss: 0.146319>
INFO:root:[Epoch 0/0, Batch 400/467] <Total loss: 0.519415> <map loss: 0.074538> <x loss: 0.105837> <y loss: 0.108795> <nbx loss: 0.116959> <nby loss: 0.113285>
INFO:root:[Epoch 0/0, Batch 410/467] <Total loss: 0.531876> <map loss: 0.076479> <x loss: 0.116666> <y loss: 0.098183> <nbx loss: 0.134837> <nby loss: 0.105710>
INFO:root:[Epoch 0/0, Batch 420/467] <Total loss: 0.559873> <map loss: 0.079071> <x loss: 0.118758> <y loss: 0.111683> <nbx loss: 0.130398> <nby loss: 0.119963>
INFO:root:[Epoch 0/0, Batch 430/467] <Total loss: 0.550167> <map loss: 0.074389> <x loss: 0.128950> <y loss: 0.099041> <nbx loss: 0.141895> <nby loss: 0.105893>
INFO:root:[Epoch 0/0, Batch 440/467] <Total loss: 0.586356> <map loss: 0.079230> <x loss: 0.122064> <y loss: 0.114609> <nbx loss: 0.142656> <nby loss: 0.127798>
INFO:root:[Epoch 0/0, Batch 450/467] <Total loss: 0.588012> <map loss: 0.080824> <x loss: 0.116879> <y loss: 0.116494> <nbx loss: 0.141699> <nby loss: 0.132116>
INFO:root:[Epoch 0/0, Batch 460/467] <Total loss: 0.563717> <map loss: 0.076925> <x loss: 0.124546> <y loss: 0.108138> <nbx loss: 0.134274> <nby loss: 0.119834>
INFO:root:###########################################
INFO:root:experiment_name: pip_32_16_60_r18_l2_l1_10_1_nb10
INFO:root:data_name: WFLW
INFO:root:det_head: pip
INFO:root:net_stride: 32
INFO:root:batch_size: 16
INFO:root:init_lr: 0.0001
INFO:root:num_epochs: 2
INFO:root:decay_steps: [30, 50]
INFO:root:input_size: 256
INFO:root:backbone: resnet18
INFO:root:pretrained: True
INFO:root:criterion_cls: l2
INFO:root:criterion_reg: l1
INFO:root:cls_loss_weight: 10
INFO:root:reg_loss_weight: 1
INFO:root:num_lms: 98
INFO:root:save_interval: 2
INFO:root:num_nb: 10
INFO:root:use_gpu: True
INFO:root:gpu_id: 2
INFO:root:###########################################
INFO:root:Epoch 0/1
INFO:root:----------
INFO:root:[Epoch 0/1, Batch 0/467] <Total loss: 2.498293> <map loss: 0.168439> <x loss: 0.482755> <y loss: 0.501879> <nbx loss: 0.680571> <nby loss: 0.664650>
INFO:root:[Epoch 0/1, Batch 10/467] <Total loss: 1.549551> <map loss: 0.152290> <x loss: 0.276421> <y loss: 0.282109> <nbx loss: 0.438037> <nby loss: 0.400694>
INFO:root:[Epoch 0/1, Batch 20/467] <Total loss: 1.334242> <map loss: 0.146385> <x loss: 0.249884> <y loss: 0.259759> <nbx loss: 0.341937> <nby loss: 0.336276>
INFO:root:[Epoch 0/1, Batch 30/467] <Total loss: 1.285550> <map loss: 0.144389> <x loss: 0.250209> <y loss: 0.239153> <nbx loss: 0.353543> <nby loss: 0.298256>
INFO:root:[Epoch 0/1, Batch 40/467] <Total loss: 1.237708> <map loss: 0.141569> <x loss: 0.241073> <y loss: 0.221785> <nbx loss: 0.346138> <nby loss: 0.287143>
INFO:root:[Epoch 0/1, Batch 50/467] <Total loss: 1.113375> <map loss: 0.134200> <x loss: 0.225383> <y loss: 0.198677> <nbx loss: 0.302959> <nby loss: 0.252155>
INFO:root:[Epoch 0/1, Batch 60/467] <Total loss: 1.049377> <map loss: 0.128661> <x loss: 0.218353> <y loss: 0.185141> <nbx loss: 0.277877> <nby loss: 0.239345>
INFO:root:[Epoch 0/1, Batch 70/467] <Total loss: 0.960758> <map loss: 0.122890> <x loss: 0.206277> <y loss: 0.159438> <nbx loss: 0.260772> <nby loss: 0.211382>
INFO:root:[Epoch 0/1, Batch 80/467] <Total loss: 0.927027> <map loss: 0.120411> <x loss: 0.191182> <y loss: 0.158352> <nbx loss: 0.256893> <nby loss: 0.200189>
INFO:root:[Epoch 0/1, Batch 90/467] <Total loss: 0.870900> <map loss: 0.113052> <x loss: 0.181807> <y loss: 0.155475> <nbx loss: 0.219283> <nby loss: 0.201282>
INFO:root:[Epoch 0/1, Batch 100/467] <Total loss: 0.862770> <map loss: 0.111865> <x loss: 0.169570> <y loss: 0.158230> <nbx loss: 0.219496> <nby loss: 0.203608>
INFO:root:[Epoch 0/1, Batch 110/467] <Total loss: 0.790485> <map loss: 0.107292> <x loss: 0.159978> <y loss: 0.143350> <nbx loss: 0.200140> <nby loss: 0.179724>
INFO:root:[Epoch 0/1, Batch 120/467] <Total loss: 0.800417> <map loss: 0.105560> <x loss: 0.154695> <y loss: 0.149967> <nbx loss: 0.207749> <nby loss: 0.182445>
INFO:root:[Epoch 0/1, Batch 130/467] <Total loss: 0.786799> <map loss: 0.104782> <x loss: 0.155379> <y loss: 0.146046> <nbx loss: 0.199011> <nby loss: 0.181581>
INFO:root:[Epoch 0/1, Batch 140/467] <Total loss: 0.806498> <map loss: 0.107036> <x loss: 0.171012> <y loss: 0.140624> <nbx loss: 0.218958> <nby loss: 0.168868>
INFO:root:[Epoch 0/1, Batch 150/467] <Total loss: 0.710712> <map loss: 0.095962> <x loss: 0.152238> <y loss: 0.131773> <nbx loss: 0.177106> <nby loss: 0.153633>
INFO:root:[Epoch 0/1, Batch 160/467] <Total loss: 0.783510> <map loss: 0.102243> <x loss: 0.165532> <y loss: 0.143193> <nbx loss: 0.208533> <nby loss: 0.164009>
INFO:root:[Epoch 0/1, Batch 170/467] <Total loss: 0.706734> <map loss: 0.096586> <x loss: 0.147251> <y loss: 0.133238> <nbx loss: 0.178951> <nby loss: 0.150708>
INFO:root:[Epoch 0/1, Batch 180/467] <Total loss: 0.640586> <map loss: 0.089312> <x loss: 0.133227> <y loss: 0.126859> <nbx loss: 0.153596> <nby loss: 0.137593>
INFO:root:[Epoch 0/1, Batch 190/467] <Total loss: 0.740909> <map loss: 0.099114> <x loss: 0.150525> <y loss: 0.144706> <nbx loss: 0.183004> <nby loss: 0.163561>
INFO:root:[Epoch 0/1, Batch 200/467] <Total loss: 0.731849> <map loss: 0.098047> <x loss: 0.160944> <y loss: 0.129597> <nbx loss: 0.194705> <nby loss: 0.148555>
INFO:root:[Epoch 0/1, Batch 210/467] <Total loss: 0.718796> <map loss: 0.096898> <x loss: 0.151711> <y loss: 0.128304> <nbx loss: 0.185555> <nby loss: 0.156328>
INFO:root:[Epoch 0/1, Batch 220/467] <Total loss: 0.662486> <map loss: 0.093496> <x loss: 0.137486> <y loss: 0.122120> <nbx loss: 0.168157> <nby loss: 0.141227>
INFO:root:[Epoch 0/1, Batch 230/467] <Total loss: 0.621163> <map loss: 0.089440> <x loss: 0.132431> <y loss: 0.114586> <nbx loss: 0.156279> <nby loss: 0.128427>
INFO:root:[Epoch 0/1, Batch 240/467] <Total loss: 0.590763> <map loss: 0.085256> <x loss: 0.117999> <y loss: 0.120594> <nbx loss: 0.135106> <nby loss: 0.131808>
INFO:root:[Epoch 0/1, Batch 250/467] <Total loss: 0.607805> <map loss: 0.084464> <x loss: 0.123345> <y loss: 0.121991> <nbx loss: 0.144793> <nby loss: 0.133213>
INFO:root:[Epoch 0/1, Batch 260/467] <Total loss: 0.627006> <map loss: 0.086925> <x loss: 0.132284> <y loss: 0.120024> <nbx loss: 0.151595> <nby loss: 0.136177>
INFO:root:[Epoch 0/1, Batch 270/467] <Total loss: 0.531146> <map loss: 0.079062> <x loss: 0.110799> <y loss: 0.105404> <nbx loss: 0.122370> <nby loss: 0.113511>
INFO:root:[Epoch 0/1, Batch 280/467] <Total loss: 0.632567> <map loss: 0.087533> <x loss: 0.130622> <y loss: 0.119936> <nbx loss: 0.152507> <nby loss: 0.141968>
INFO:root:[Epoch 0/1, Batch 290/467] <Total loss: 0.704760> <map loss: 0.093091> <x loss: 0.140853> <y loss: 0.138056> <nbx loss: 0.173944> <nby loss: 0.158815>
INFO:root:[Epoch 0/1, Batch 300/467] <Total loss: 0.629741> <map loss: 0.086509> <x loss: 0.128954> <y loss: 0.121151> <nbx loss: 0.155871> <nby loss: 0.137255>
INFO:root:[Epoch 0/1, Batch 310/467] <Total loss: 0.599511> <map loss: 0.083930> <x loss: 0.125834> <y loss: 0.115553> <nbx loss: 0.145120> <nby loss: 0.129075>
INFO:root:[Epoch 0/1, Batch 320/467] <Total loss: 0.577655> <map loss: 0.082467> <x loss: 0.124226> <y loss: 0.110419> <nbx loss: 0.138166> <nby loss: 0.122376>
INFO:root:[Epoch 0/1, Batch 330/467] <Total loss: 0.660547> <map loss: 0.090463> <x loss: 0.136046> <y loss: 0.122360> <nbx loss: 0.176967> <nby loss: 0.134711>
INFO:root:[Epoch 0/1, Batch 340/467] <Total loss: 0.617787> <map loss: 0.085066> <x loss: 0.130893> <y loss: 0.117541> <nbx loss: 0.151132> <nby loss: 0.133155>
INFO:root:[Epoch 0/1, Batch 350/467] <Total loss: 0.631431> <map loss: 0.082083> <x loss: 0.144668> <y loss: 0.115341> <nbx loss: 0.160981> <nby loss: 0.128359>
INFO:root:[Epoch 0/1, Batch 360/467] <Total loss: 0.557709> <map loss: 0.079762> <x loss: 0.115875> <y loss: 0.108323> <nbx loss: 0.136555> <nby loss: 0.117194>
INFO:root:[Epoch 0/1, Batch 370/467] <Total loss: 0.540122> <map loss: 0.075862> <x loss: 0.115594> <y loss: 0.103080> <nbx loss: 0.131017> <nby loss: 0.114570>
INFO:root:[Epoch 0/1, Batch 380/467] <Total loss: 0.618920> <map loss: 0.083049> <x loss: 0.126209> <y loss: 0.119102> <nbx loss: 0.151676> <nby loss: 0.138885>
INFO:root:[Epoch 0/1, Batch 390/467] <Total loss: 0.549686> <map loss: 0.078133> <x loss: 0.111602> <y loss: 0.110238> <nbx loss: 0.128518> <nby loss: 0.121195>
INFO:root:[Epoch 0/1, Batch 400/467] <Total loss: 0.549442> <map loss: 0.079848> <x loss: 0.120428> <y loss: 0.100200> <nbx loss: 0.139100> <nby loss: 0.109867>
INFO:root:[Epoch 0/1, Batch 410/467] <Total loss: 0.569714> <map loss: 0.077372> <x loss: 0.118010> <y loss: 0.114093> <nbx loss: 0.136216> <nby loss: 0.124023>
INFO:root:[Epoch 0/1, Batch 420/467] <Total loss: 0.561160> <map loss: 0.079760> <x loss: 0.115304> <y loss: 0.112505> <nbx loss: 0.131373> <nby loss: 0.122217>
INFO:root:[Epoch 0/1, Batch 430/467] <Total loss: 0.535306> <map loss: 0.074087> <x loss: 0.122465> <y loss: 0.100256> <nbx loss: 0.133362> <nby loss: 0.105136>
INFO:root:[Epoch 0/1, Batch 440/467] <Total loss: 0.593760> <map loss: 0.081851> <x loss: 0.127328> <y loss: 0.112881> <nbx loss: 0.141630> <nby loss: 0.130071>
INFO:root:[Epoch 0/1, Batch 450/467] <Total loss: 0.620248> <map loss: 0.084843> <x loss: 0.128931> <y loss: 0.121676> <nbx loss: 0.146901> <nby loss: 0.137897>
INFO:root:[Epoch 0/1, Batch 460/467] <Total loss: 0.569677> <map loss: 0.076847> <x loss: 0.128118> <y loss: 0.106944> <nbx loss: 0.140957> <nby loss: 0.116812>
INFO:root:Epoch 1/1
INFO:root:----------
INFO:root:[Epoch 1/1, Batch 0/467] <Total loss: 0.551385> <map loss: 0.078572> <x loss: 0.122808> <y loss: 0.101459> <nbx loss: 0.137592> <nby loss: 0.110954>
INFO:root:[Epoch 1/1, Batch 10/467] <Total loss: 0.503868> <map loss: 0.072258> <x loss: 0.110527> <y loss: 0.100799> <nbx loss: 0.114304> <nby loss: 0.105979>
INFO:root:[Epoch 1/1, Batch 20/467] <Total loss: 0.681612> <map loss: 0.082975> <x loss: 0.160769> <y loss: 0.120274> <nbx loss: 0.185660> <nby loss: 0.131934>
INFO:root:[Epoch 1/1, Batch 30/467] <Total loss: 0.470730> <map loss: 0.066295> <x loss: 0.103159> <y loss: 0.089469> <nbx loss: 0.117672> <nby loss: 0.094135>
INFO:root:[Epoch 1/1, Batch 40/467] <Total loss: 0.551367> <map loss: 0.076268> <x loss: 0.123920> <y loss: 0.099951> <nbx loss: 0.138009> <nby loss: 0.113219>
INFO:root:[Epoch 1/1, Batch 50/467] <Total loss: 0.559557> <map loss: 0.076432> <x loss: 0.117254> <y loss: 0.110382> <nbx loss: 0.136146> <nby loss: 0.119343>
INFO:root:[Epoch 1/1, Batch 60/467] <Total loss: 0.609029> <map loss: 0.082728> <x loss: 0.134643> <y loss: 0.113615> <nbx loss: 0.154804> <nby loss: 0.123238>
INFO:root:[Epoch 1/1, Batch 70/467] <Total loss: 0.595584> <map loss: 0.077581> <x loss: 0.131200> <y loss: 0.113334> <nbx loss: 0.150530> <nby loss: 0.122939>
INFO:root:[Epoch 1/1, Batch 80/467] <Total loss: 0.557518> <map loss: 0.075250> <x loss: 0.124051> <y loss: 0.106562> <nbx loss: 0.138438> <nby loss: 0.113216>
INFO:root:[Epoch 1/1, Batch 90/467] <Total loss: 0.518998> <map loss: 0.074808> <x loss: 0.112485> <y loss: 0.099810> <nbx loss: 0.127543> <nby loss: 0.104352>
INFO:root:[Epoch 1/1, Batch 100/467] <Total loss: 0.530640> <map loss: 0.075239> <x loss: 0.111742> <y loss: 0.105612> <nbx loss: 0.123066> <nby loss: 0.114980>
INFO:root:[Epoch 1/1, Batch 110/467] <Total loss: 0.516251> <map loss: 0.073848> <x loss: 0.110645> <y loss: 0.101138> <nbx loss: 0.123812> <nby loss: 0.106807>
INFO:root:[Epoch 1/1, Batch 120/467] <Total loss: 0.544378> <map loss: 0.075620> <x loss: 0.116583> <y loss: 0.105369> <nbx loss: 0.130720> <nby loss: 0.116087>
INFO:root:[Epoch 1/1, Batch 130/467] <Total loss: 0.622974> <map loss: 0.084482> <x loss: 0.126213> <y loss: 0.121268> <nbx loss: 0.150854> <nby loss: 0.140158>
INFO:root:[Epoch 1/1, Batch 140/467] <Total loss: 0.497939> <map loss: 0.070364> <x loss: 0.107708> <y loss: 0.095544> <nbx loss: 0.121432> <nby loss: 0.102891>
INFO:root:[Epoch 1/1, Batch 150/467] <Total loss: 0.511095> <map loss: 0.071154> <x loss: 0.113717> <y loss: 0.098954> <nbx loss: 0.123931> <nby loss: 0.103339>
INFO:root:[Epoch 1/1, Batch 160/467] <Total loss: 0.600745> <map loss: 0.082362> <x loss: 0.131187> <y loss: 0.107374> <nbx loss: 0.154350> <nby loss: 0.125471>
INFO:root:[Epoch 1/1, Batch 170/467] <Total loss: 0.606169> <map loss: 0.080027> <x loss: 0.130460> <y loss: 0.117844> <nbx loss: 0.150685> <nby loss: 0.127153>
INFO:root:[Epoch 1/1, Batch 180/467] <Total loss: 0.497314> <map loss: 0.070687> <x loss: 0.111340> <y loss: 0.096725> <nbx loss: 0.117036> <nby loss: 0.101526>
INFO:root:[Epoch 1/1, Batch 190/467] <Total loss: 0.553950> <map loss: 0.076764> <x loss: 0.121476> <y loss: 0.100337> <nbx loss: 0.142930> <nby loss: 0.112444>
INFO:root:[Epoch 1/1, Batch 200/467] <Total loss: 0.577798> <map loss: 0.079171> <x loss: 0.126405> <y loss: 0.107096> <nbx loss: 0.147959> <nby loss: 0.117166>
INFO:root:[Epoch 1/1, Batch 210/467] <Total loss: 0.569034> <map loss: 0.078582> <x loss: 0.117338> <y loss: 0.106234> <nbx loss: 0.145670> <nby loss: 0.121209>
INFO:root:[Epoch 1/1, Batch 220/467] <Total loss: 0.569474> <map loss: 0.075344> <x loss: 0.121008> <y loss: 0.115673> <nbx loss: 0.134585> <nby loss: 0.122865>
INFO:root:[Epoch 1/1, Batch 230/467] <Total loss: 0.570687> <map loss: 0.074866> <x loss: 0.115935> <y loss: 0.118819> <nbx loss: 0.131891> <nby loss: 0.129176>
INFO:root:[Epoch 1/1, Batch 240/467] <Total loss: 0.519692> <map loss: 0.073314> <x loss: 0.109264> <y loss: 0.100147> <nbx loss: 0.124478> <nby loss: 0.112490>
INFO:root:[Epoch 1/1, Batch 250/467] <Total loss: 0.495287> <map loss: 0.073190> <x loss: 0.102702> <y loss: 0.095119> <nbx loss: 0.117756> <nby loss: 0.106520>
INFO:root:[Epoch 1/1, Batch 260/467] <Total loss: 0.506483> <map loss: 0.071949> <x loss: 0.107425> <y loss: 0.102478> <nbx loss: 0.115231> <nby loss: 0.109400>
INFO:root:[Epoch 1/1, Batch 270/467] <Total loss: 0.563033> <map loss: 0.074585> <x loss: 0.121496> <y loss: 0.107978> <nbx loss: 0.139554> <nby loss: 0.119421>
INFO:root:[Epoch 1/1, Batch 280/467] <Total loss: 0.473803> <map loss: 0.066133> <x loss: 0.105217> <y loss: 0.092686> <nbx loss: 0.113977> <nby loss: 0.095790>
INFO:root:[Epoch 1/1, Batch 290/467] <Total loss: 0.563599> <map loss: 0.074096> <x loss: 0.116587> <y loss: 0.111719> <nbx loss: 0.133884> <nby loss: 0.127312>
INFO:root:[Epoch 1/1, Batch 300/467] <Total loss: 0.539133> <map loss: 0.075780> <x loss: 0.113660> <y loss: 0.104144> <nbx loss: 0.131320> <nby loss: 0.114228>
INFO:root:[Epoch 1/1, Batch 310/467] <Total loss: 0.518120> <map loss: 0.070601> <x loss: 0.113647> <y loss: 0.099014> <nbx loss: 0.128966> <nby loss: 0.105893>
INFO:root:[Epoch 1/1, Batch 320/467] <Total loss: 0.497654> <map loss: 0.071338> <x loss: 0.103759> <y loss: 0.101163> <nbx loss: 0.115249> <nby loss: 0.106145>
INFO:root:[Epoch 1/1, Batch 330/467] <Total loss: 0.556888> <map loss: 0.076432> <x loss: 0.118508> <y loss: 0.105451> <nbx loss: 0.138190> <nby loss: 0.118306>
INFO:root:[Epoch 1/1, Batch 340/467] <Total loss: 0.470781> <map loss: 0.068213> <x loss: 0.099512> <y loss: 0.090537> <nbx loss: 0.113945> <nby loss: 0.098574>
INFO:root:[Epoch 1/1, Batch 350/467] <Total loss: 0.554536> <map loss: 0.070255> <x loss: 0.122085> <y loss: 0.107182> <nbx loss: 0.138782> <nby loss: 0.116232>
INFO:root:[Epoch 1/1, Batch 360/467] <Total loss: 0.497382> <map loss: 0.072967> <x loss: 0.105147> <y loss: 0.099670> <nbx loss: 0.113680> <nby loss: 0.105919>
INFO:root:[Epoch 1/1, Batch 370/467] <Total loss: 0.455723> <map loss: 0.063308> <x loss: 0.104543> <y loss: 0.083929> <nbx loss: 0.113081> <nby loss: 0.090862>
INFO:root:[Epoch 1/1, Batch 380/467] <Total loss: 0.473326> <map loss: 0.067995> <x loss: 0.104136> <y loss: 0.093144> <nbx loss: 0.111870> <nby loss: 0.096181>
INFO:root:[Epoch 1/1, Batch 390/467] <Total loss: 0.602352> <map loss: 0.078182> <x loss: 0.133791> <y loss: 0.111890> <nbx loss: 0.153599> <nby loss: 0.124890>
INFO:root:[Epoch 1/1, Batch 400/467] <Total loss: 0.517808> <map loss: 0.070275> <x loss: 0.110005> <y loss: 0.103960> <nbx loss: 0.125809> <nby loss: 0.107759>
INFO:root:[Epoch 1/1, Batch 410/467] <Total loss: 0.510047> <map loss: 0.071957> <x loss: 0.106801> <y loss: 0.101239> <nbx loss: 0.120042> <nby loss: 0.110008>
INFO:root:[Epoch 1/1, Batch 420/467] <Total loss: 0.592273> <map loss: 0.079172> <x loss: 0.124976> <y loss: 0.112529> <nbx loss: 0.150329> <nby loss: 0.125268>
INFO:root:[Epoch 1/1, Batch 430/467] <Total loss: 0.570700> <map loss: 0.072971> <x loss: 0.132182> <y loss: 0.102321> <nbx loss: 0.152707> <nby loss: 0.110519>
INFO:root:[Epoch 1/1, Batch 440/467] <Total loss: 0.461776> <map loss: 0.067083> <x loss: 0.101846> <y loss: 0.085364> <nbx loss: 0.118561> <nby loss: 0.088922>
INFO:root:[Epoch 1/1, Batch 450/467] <Total loss: 0.476466> <map loss: 0.068487> <x loss: 0.110035> <y loss: 0.088577> <nbx loss: 0.119773> <nby loss: 0.089594>
INFO:root:[Epoch 1/1, Batch 460/467] <Total loss: 0.517498> <map loss: 0.072485> <x loss: 0.117594> <y loss: 0.091101> <nbx loss: 0.135380> <nby loss: 0.100938>
INFO:root:nme: 0.06542097294948933
INFO:root:fr : 0.1412
INFO:root:auc: 0.43424360000000006
